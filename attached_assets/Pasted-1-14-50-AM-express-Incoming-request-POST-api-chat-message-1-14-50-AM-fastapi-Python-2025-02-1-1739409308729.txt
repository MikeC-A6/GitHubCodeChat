1:14:50 AM [express] Incoming request: POST /api/chat/message
1:14:50 AM [fastapi] Python: 2025-02-13 01:14:50,950 - backend.api.routes.chat - INFO - Received chat request: [14]
2025-02-13 01:14:50,950 - backend.api.routes.chat - INFO - Processing chat request...

1:14:50 AM [fastapi] Python: 2025-02-13 01:14:50,954 - backend.services.llama.service - INFO - Processing chat request for repositories: [14]
2025-02-13 01:14:50,954 - backend.services.llama.service - INFO - Message: what does this app do?
2025-02-13 01:14:50,954 - backend.services.llama.service - INFO - Chat history length: 0

1:14:50 AM [fastapi] Python: 2025-02-13 01:14:50,955 - backend.services.llama.service - INFO - Created metadata filter: filters=[MetadataFilter(key='repository_id', value=['14'], operator=<FilterOperator.IN: 'in'>)] condition=<FilterCondition.AND: 'and'>
2025-02-13 01:14:50,955 - backend.services.llama.service - INFO - Retrieved vector store

1:14:50 AM [fastapi] Python: 2025-02-13 01:14:50,957 - backend.services.llama.service - INFO - Created vector store index
2025-02-13 01:14:50,957 - backend.services.llama.service - INFO - Using retrieval config: {'chat_mode': 'condense_plus_context', 'verbose': True, 'similarity_top_k': 20}

1:14:50 AM [fastapi] Python: 2025-02-13 01:14:50,958 - backend.services.llama.service - INFO - Created chat engine
2025-02-13 01:14:50,958 - backend.services.llama.service - INFO - Formatted chat history: 0 messages
2025-02-13 01:14:50,958 - backend.services.llama.service - INFO - Querying chat engine...
2025-02-13 01:14:50,959 - llama_index.core.chat_engine.condense_plus_context - INFO - Condensed question: what does this app do?

1:14:51 AM [fastapi] Python: Condensed question: what does this app do?
2025-02-13 01:14:51,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"

1:14:51 AM [fastapi] Python: 2025-02-13 01:14:51,548 - backend.services.llama.service - ERROR - Error in chat: 'CondensePlusContextChatEngine' object has no attribute 'retriever'
Traceback (most recent call last):
  File "/home/runner/workspace/backend/services/llama/service.py", line 131, in chat
    logger.info(f"Retrieved nodes from vector store: {chat_engine.retriever.retrieve(message)}")
                                                      ^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'CondensePlusContextChatEngine' object has no attribute 'retriever'

1:14:51 AM [fastapi] Python: 2025-02-13 01:14:51,551 - backend.api.routes.chat - ERROR - Chat error: Failed to process chat message: 'CondensePlusContextChatEngine' object has no attribute 'retriever'

1:14:51 AM [fastapi] Python: INFO:     10.81.3.82:0 - "POST /chat/message HTTP/1.1" 500 Internal Server Error